{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U \"torch==2.1.2\" tensorboard\n",
        "!pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\"\n"
      ],
      "metadata": {
        "id": "6cmTr9Lgzr-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n",
        "!pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f\n"
      ],
      "metadata": {
        "id": "ISseX4ELz0Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import bitsandbytes as bnb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, PeftConfig\n",
        "from trl import SFTTrainer\n",
        "from trl import setup_chat_format\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          pipeline,\n",
        "                          logging)\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n"
      ],
      "metadata": {
        "id": "3luZu392-KFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print PyTorch version and set device to CUDA if available, otherwise to CPU\n",
        "print(f\"Using PyTorch version {torch.__version__}\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define file path for data\n",
        "filename = \"../input/sentiment-analysis/all-data.json\"\n",
        "\n",
        "# Read CSV file into a DataFrame, specifying column names and encoding\n",
        "df = pd.read_csv(filename, names=[\"sentiment\", \"text\"], encoding=\"utf-8\", encoding_errors=\"replace\")\n",
        "\n",
        "# Split data into train, test, and evaluation sets for each sentiment category\n",
        "X_train = []\n",
        "X_test = []\n",
        "for sentiment in [\"positive\", \"neutral\", \"negative\"]:\n",
        "    train, test = train_test_split(df[df.sentiment == sentiment], train_size=300, test_size=300, random_state=42)\n",
        "    X_train.append(train)\n",
        "    X_test.append(test)\n",
        "\n",
        "# Concatenate and shuffle train and test sets\n",
        "X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
        "X_test = pd.concat(X_test)\n",
        "\n",
        "# Select evaluation data\n",
        "eval_idx = [idx for idx in df.index if idx not in list(train.index) + list(test.index)]\n",
        "X_eval = df[df.index.isin(eval_idx)]\n",
        "X_eval = (X_eval.groupby('sentiment', group_keys=False)\n",
        "          .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "\n",
        "# Define functions to generate prompts for training and evaluation data\n",
        "def generate_prompt(data_point):\n",
        "    return f\"Analyze the sentiment of the news headline enclosed in square brackets, determine if it is positive, neutral, or negative, and return the answer as the corresponding sentiment label \\\"positive\\\" or \\\"neutral\\\" or \\\"negative\\\".\\n\\n[{data_point['text']}] = {data_point['sentiment']}\"\n",
        "\n",
        "def generate_test_prompt(data_point):\n",
        "    return f\"Analyze the sentiment of the news headline enclosed in square brackets, determine if it is positive, neutral, or negative, and return the answer as the corresponding sentiment label \\\"positive\\\" or \\\"neutral\\\" or \\\"negative\\\".\\n\\n[{data_point['text']}] =\"\n",
        "\n",
        "# Apply prompt generation functions to train, evaluation, and test data\n",
        "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
        "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
        "y_true = X_test.sentiment\n",
        "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
        "\n",
        "# Create datasets from pandas DataFrames\n",
        "train_data = Dataset.from_pandas(X_train)\n",
        "eval_data = Dataset.from_pandas(X_eval)\n"
      ],
      "metadata": {
        "id": "FldhLRukz2e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation function\n",
        "def evaluate(y_true, y_pred):\n",
        "    # Define labels and mapping for sentiment categories\n",
        "    labels = ['positive', 'neutral', 'negative']\n",
        "    mapping = {'positive': 2, 'neutral': 1, 'none': 1, 'negative': 0}\n",
        "\n",
        "    # Define function to map sentiment labels to numerical values\n",
        "    def map_func(x):\n",
        "        return mapping.get(x, 1)\n",
        "\n",
        "    # Map true and predicted labels to numerical values\n",
        "    y_true = np.vectorize(map_func)(y_true)\n",
        "    y_pred = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "    print(f'Accuracy: {accuracy:.3f}')\n",
        "\n",
        "    # Generate accuracy report for each label\n",
        "    unique_labels = set(y_true)\n",
        "    for label in unique_labels:\n",
        "        label_indices = [i for i in range(len(y_true)) if y_true[i] == label]\n",
        "        label_y_true = [y_true[i] for i in label_indices]\n",
        "        label_y_pred = [y_pred[i] for i in label_indices]\n",
        "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
        "        print(f'Accuracy for label {label}: {label_accuracy:.3f}')\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
        "\n",
        "# Define model and tokenizer configurations\n",
        "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "# Define configuration for BitsAndBytes quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Load model with specified configurations\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=device,\n",
        "    torch_dtype=compute_dtype,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "# Disable model caching and set pretraining token probability\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load tokenizer and set padding configurations\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Setup chat format for the model\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)"
      ],
      "metadata": {
        "id": "fFZrcjZO-Hgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test, model, tokenizer):\n",
        "    y_pred = []\n",
        "    for i in tqdm(range(len(test))):\n",
        "        prompt = test.iloc[i][\"text\"]\n",
        "        pipe = pipeline(task=\"text-generation\",\n",
        "                        model=model,\n",
        "                        tokenizer=tokenizer,\n",
        "                        max_new_tokens=1,\n",
        "                        temperature=0.0,\n",
        "                       )\n",
        "        result = pipe(prompt)\n",
        "        answer = result[0]['generated_text'].split(\"=\")[-1]\n",
        "        if \"positive\" in answer:\n",
        "            y_pred.append(\"positive\")\n",
        "        elif \"negative\" in answer:\n",
        "            y_pred.append(\"negative\")\n",
        "        elif \"neutral\" in answer:\n",
        "            y_pred.append(\"neutral\")\n",
        "        else:\n",
        "            y_pred.append(\"none\")\n",
        "    return y_pred\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = predict(X_test, model, tokenizer)\n",
        "\n",
        "# Evaluate predictions\n",
        "evaluate(y_true, y_pred)\n",
        "\n",
        "# Define output directory for trained weights\n",
        "output_dir = \"trained_weights\"\n",
        "\n",
        "# Configure Lora model\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Define training arguments\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=0,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=\"tensorboard\",\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=1024,\n",
        "    packing=False,\n",
        "    dataset_kwargs={\n",
        "        \"add_special_tokens\": False,\n",
        "        \"append_concat_token\": False,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save trained model and tokenizer\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Load tensorboard extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Launch tensorboard for visualization\n",
        "%tensorboard --logdir logs/runs\n",
        "\n",
        "# Clean up memory\n",
        "import gc\n",
        "\n",
        "del [model, tokenizer, peft_config, trainer, train_data, eval_data]\n",
        "del [training_arguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]\n",
        "\n",
        "# Clear GPU memory\n",
        "for _ in range(100):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Load fine-tuned model using AutoPeftModelForCausalLM\n",
        "finetuned_model_dir = \"./trained_weights/\"\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
        "\n",
        "finetuned_model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "     finetuned_model_dir,\n",
        "     torch_dtype=compute_dtype,\n",
        "     return_dict=False,\n",
        "     low_cpu_mem_usage=True,\n",
        "     device_map=device,\n",
        ")\n",
        "\n",
        "# Merge and unload model for efficient inference\n",
        "merged_model = finetuned_model.merge_and_unload()\n",
        "merged_model.save_pretrained(\"./merged_model\", safe_serialization=True, max_shard_size=\"2GB\")\n",
        "tokenizer.save_pretrained(\"./merged_model\")\n"
      ],
      "metadata": {
        "id": "pO6EnMNK-Dfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IbWuASC3REP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}